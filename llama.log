[1715089207] warming up the model with an empty run
[1715089208] 
llama server listening at http://127.0.0.1:8080

